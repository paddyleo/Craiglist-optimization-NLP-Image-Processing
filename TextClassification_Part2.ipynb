{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text_Neha.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "em6ZR9UgSxHE"
      },
      "source": [
        "#loading the unprocessed data\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import nltk\n",
        "from google.colab import drive\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.pipeline import FeatureUnion\n",
        "import re\n",
        "import string\n",
        "from scipy.sparse import hstack, csr_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import RidgeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn import model_selection, naive_bayes, svm\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import os"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHK2PZGsUC5S"
      },
      "source": [
        "#drive.mount('/content/drive')\n",
        "#os.chdir(\"/content/drive/My Drive/\")"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "lSZGbjDkTZMe",
        "outputId": "f5f89b05-da49-4331-c310-66443e0e263e"
      },
      "source": [
        "  project_data = pd.read_csv('Text classification/craiglist_1.2k_appliances_data.csv')\n",
        "  project_data.head()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>link</th>\n",
              "      <th>Title</th>\n",
              "      <th>Description</th>\n",
              "      <th>Price</th>\n",
              "      <th>Condition</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>https://tippecanoe.craigslist.org/app/d/montic...</td>\n",
              "      <td>maytag electric dryer - $150</td>\n",
              "      <td>maytag electric steam dryer, $150. obo. i have...</td>\n",
              "      <td>$150</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>https://tippecanoe.craigslist.org/app/d/fisher...</td>\n",
              "      <td>Platinum GE Washer and Dryer - $495 (Fishers)</td>\n",
              "      <td>We are selling our like new set of Platinum GE...</td>\n",
              "      <td>$495</td>\n",
              "      <td>like new</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>https://tippecanoe.craigslist.org/ppd/d/washer...</td>\n",
              "      <td>WASHERS*WASHERS*WASHERS* $$$ SAVE $$$* DRYERS*...</td>\n",
              "      <td>SAMSUNG SUPER Capacity Multi Cycle Washer (STA...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>https://tippecanoe.craigslist.org/app/d/lafaye...</td>\n",
              "      <td>*ESTATE SALE* Hotpoint Electric Range - $40 (L...</td>\n",
              "      <td>*****ESTATE SALE*****Hotpoint Electric RangeMo...</td>\n",
              "      <td>$40</td>\n",
              "      <td>good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>https://tippecanoe.craigslist.org/app/d/lafaye...</td>\n",
              "      <td>*PRICE REDUCED / ESTATE SALE* Maytag Dishwashe...</td>\n",
              "      <td>*****ESTATE SALE*****Maytag DishwasherModel WU300</td>\n",
              "      <td>$15</td>\n",
              "      <td>good</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                link  ... Condition\n",
              "0  https://tippecanoe.craigslist.org/app/d/montic...  ...       NaN\n",
              "1  https://tippecanoe.craigslist.org/app/d/fisher...  ...  like new\n",
              "2  https://tippecanoe.craigslist.org/ppd/d/washer...  ...       NaN\n",
              "3  https://tippecanoe.craigslist.org/app/d/lafaye...  ...      good\n",
              "4  https://tippecanoe.craigslist.org/app/d/lafaye...  ...      good\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIIbwSQfTbod"
      },
      "source": [
        "project_data['Description'] = project_data['Description'].fillna('Unknown')"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pEsAg6tkJB4"
      },
      "source": [
        "project_data['Description_char'] = project_data['Description'].values"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZTduWnwirou"
      },
      "source": [
        "project_data['ex_flag'] = project_data['Description'].str.contains('excellent|Excellent').astype(int)\n",
        "project_data['new_flag'] = project_data['Description'].str.contains('new|New').astype(int)\n",
        "project_data['go_flag'] = project_data['Description'].str.contains('good|Good').astype(int)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TffWuctZZcJz",
        "outputId": "160ca5a6-06b1-478f-d7b2-e6a7c5504265"
      },
      "source": [
        "filtered_data = project_data[~project_data['Condition'].isna()]\n",
        "filtered_data = filtered_data[~project_data['Price'].isna()]\n",
        "filtered_data['Price'] = filtered_data['Price'].str.replace('$', '').str.replace(',', '').astype('float')\n",
        "filtered_data['summary_size']     = filtered_data['Description'].apply(lambda x: len(x))\n",
        "filtered_data['words_in_summary'] = filtered_data['Description'].apply(lambda x: len(x.split()))\n",
        "filtered_data['Condition'] = filtered_data['Condition'].map({'excellent': 1, 'new': 1, 'good':0, 'like new':0, 'fair':0 })\n",
        "filtered_data = filtered_data[~filtered_data['Condition'].isna()]\n",
        "\n",
        "filtered_data.shape"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(798, 11)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cxhww_nmk2Zp",
        "outputId": "9c31d157-3912-4e27-89a4-05d311017daf"
      },
      "source": [
        "filtered_data['Condition'].value_counts(normalize=True)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0    0.545113\n",
              "0.0    0.454887\n",
              "Name: Condition, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6dJZ9iwnVI9p"
      },
      "source": [
        "default_preprocessor = CountVectorizer().build_preprocessor()\n",
        "def build_text_preprocessor(field):\n",
        "  field_idx = list(filtered_data.columns).index(field)\n",
        "  return lambda x: default_preprocessor(x[field_idx])\n",
        "\n",
        "re_tok = re.compile(f'([{string.punctuation}''])')\n",
        "def tokenize(s):\n",
        "  return re_tok.sub(r' ', s).split(' ')"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18OWN_cQVJb8"
      },
      "source": [
        "text_vectorizer = FeatureUnion([\n",
        "                                ('Description', TfidfVectorizer(ngram_range=(1,3), tokenizer=tokenize, min_df=0.01, max_df=0.9,\n",
        "                                                                strip_accents='unicode',use_idf=1, smooth_idf=1, sublinear_tf=1,\n",
        "                                                                preprocessor = build_text_preprocessor('Description'))),\n",
        "                                ('Description_char', TfidfVectorizer(ngram_range=(1,4), tokenizer=tokenize, analyzer='char', \n",
        "                                                                     stop_words='english', strip_accents='unicode',\n",
        "                                                                     max_features=10000,\n",
        "                                                                preprocessor = build_text_preprocessor('Description_char'))),\n",
        "                                ('Title', TfidfVectorizer(ngram_range=(1,3), tokenizer=tokenize, min_df=0.01, max_df=0.9,\n",
        "                                                                strip_accents='unicode',use_idf=1, smooth_idf=1, sublinear_tf=1,\n",
        "                                                                preprocessor = build_text_preprocessor('Title')))\n",
        "                              ])\n",
        "train_tfidf = text_vectorizer.fit_transform(filtered_data.values)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5xpoUiSwCeF"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2qJZUKRVJuf"
      },
      "source": [
        "numeric_features = csr_matrix(filtered_data[[ 'summary_size', 'words_in_summary', 'Price', 'ex_flag', 'new_flag', 'go_flag']].values)\n",
        "train_idf = hstack((train_tfidf, numeric_features)).toarray()"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BatITwwTbQc9"
      },
      "source": [
        "y = filtered_data['Condition']"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsUTup4oVKEM"
      },
      "source": [
        "X_train, X_valid, y_train, y_valid = train_test_split(train_idf, y, test_size=0.2, random_state=1, stratify = y )"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0nMUc4pbeEt",
        "outputId": "36b58cf0-0074-454c-880d-3c5837d7be72"
      },
      "source": [
        "classifier = RidgeClassifier(alpha=.0001)\n",
        "classifier.fit(X_train, y_train)\n",
        "pred_tfidf = classifier.decision_function(X_valid)\n",
        "probs_tfidf = np.exp(pred_tfidf)\n",
        "pred_tfidf = np.where(probs_tfidf>0.90, 1, 0)\n",
        "accuracy_val = accuracy_score(y_valid, pred_tfidf)\n",
        "accuracy_val"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7125"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OPNhaGxwbeHK",
        "outputId": "ca544fb4-589b-4e90-ede2-2b2aa9ec6604"
      },
      "source": [
        "filtered_data['Condition'].value_counts(normalize=True)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0    0.545113\n",
              "0.0    0.454887\n",
              "Name: Condition, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "owWo0_bobeJ8",
        "outputId": "8407aefe-1aab-48cf-f5f5-76e7909a243f"
      },
      "source": [
        "gnb = GaussianNB()\n",
        "y_pred = gnb.fit(X_train, y_train).predict(X_valid)\n",
        "accuracy_gb = accuracy_score(y_valid, y_pred)\n",
        "print(\"Gaussian Naive Bayes Accuracy Score -> \",accuracy_gb*100)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gaussian Naive Bayes Accuracy Score ->  66.25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rDDyJGv-bePJ",
        "outputId": "94394424-a846-4a38-8e57-a57df5cab8b0"
      },
      "source": [
        "Naive = naive_bayes.MultinomialNB()\n",
        "Naive.fit(X_train,y_train)\n",
        "predictions_NB = Naive.predict(X_valid)\n",
        "print(\"Naive Bayes Accuracy Score -> \",accuracy_score(predictions_NB, y_valid)*100)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes Accuracy Score ->  60.62499999999999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hSJNwqFxbeSj"
      },
      "source": [
        "# SVM = svm.SVC(C=1.0, kernel='linear', degree=3, gamma='auto')\n",
        "# SVM.fit(X_train,y_train)\n",
        "# predictions_SVM = SVM.predict(X_valid)# Use accuracy_score function to get the accuracy\n",
        "# print(\"SVM Accuracy Score -> \",accuracy_score(predictions_SVM, y_valid)*100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kl6Ye2_ewGT8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f6d4187-c378-4766-b79e-0fe68e027a30"
      },
      "source": [
        "#Random Forest Classifier\n",
        "random_forest = RandomForestClassifier(n_estimators=50)\n",
        "y_pred_rf = random_forest.fit(X_train,y_train).predict(X_valid)\n",
        "accuracy_rf = accuracy_score(y_pred_rf, y_valid)\n",
        "print(\"Random Forest Accuracy Score -> \",accuracy_rf*100)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Accuracy Score ->  70.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4liK7_jwGid"
      },
      "source": [
        "\n",
        "import pandas as pd\n",
        "from keras.preprocessing import text,sequence\n",
        "import numpy as np\n",
        "from keras.layers import GRU, Conv1D,CuDNNGRU\n",
        "from keras.layers import Bidirectional, GlobalAveragePooling1D, GlobalMaxPooling1D, concatenate, SpatialDropout1D\n",
        "from keras.callbacks import Callback,EarlyStopping\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Dense, Input, Embedding, Dropout, Conv1D\n",
        "from keras.models import Model, load_model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import accuracy_score,roc_auc_score,f1_score\n",
        "import re,string\n",
        "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.pipeline import FeatureUnion\n",
        "from scipy import sparse\n",
        "from scipy.sparse import hstack, csr_matrix\n",
        "from keras.models import model_from_json\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "d9fj2-mOxPAt",
        "outputId": "a153876d-43ff-4a48-db1d-53882c154c79"
      },
      "source": [
        "filtered_data.head()"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>link</th>\n",
              "      <th>Title</th>\n",
              "      <th>Description</th>\n",
              "      <th>Price</th>\n",
              "      <th>Condition</th>\n",
              "      <th>Description_char</th>\n",
              "      <th>ex_flag</th>\n",
              "      <th>new_flag</th>\n",
              "      <th>go_flag</th>\n",
              "      <th>summary_size</th>\n",
              "      <th>words_in_summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>https://tippecanoe.craigslist.org/app/d/fisher...</td>\n",
              "      <td>Platinum GE Washer and Dryer - $495 (Fishers)</td>\n",
              "      <td>We are selling our like new set of Platinum GE...</td>\n",
              "      <td>495.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>We are selling our like new set of Platinum GE...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>472</td>\n",
              "      <td>83</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>https://tippecanoe.craigslist.org/app/d/lafaye...</td>\n",
              "      <td>*ESTATE SALE* Hotpoint Electric Range - $40 (L...</td>\n",
              "      <td>*****ESTATE SALE*****Hotpoint Electric RangeMo...</td>\n",
              "      <td>40.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>*****ESTATE SALE*****Hotpoint Electric RangeMo...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>151</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>https://tippecanoe.craigslist.org/app/d/lafaye...</td>\n",
              "      <td>*PRICE REDUCED / ESTATE SALE* Maytag Dishwashe...</td>\n",
              "      <td>*****ESTATE SALE*****Maytag DishwasherModel WU300</td>\n",
              "      <td>15.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>*****ESTATE SALE*****Maytag DishwasherModel WU300</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>49</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>https://tippecanoe.craigslist.org/app/d/fisher...</td>\n",
              "      <td>Roper Washer and Dryer - $325 (Fishers)</td>\n",
              "      <td>Whirlpool Roper Washer and Electric Dryer. Abo...</td>\n",
              "      <td>325.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Whirlpool Roper Washer and Electric Dryer. Abo...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>209</td>\n",
              "      <td>34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>https://tippecanoe.craigslist.org/app/d/lafaye...</td>\n",
              "      <td>Front load washer - $250 (Lafayette downtown)</td>\n",
              "      <td>I have a Crosley front load washer that was us...</td>\n",
              "      <td>250.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>I have a Crosley front load washer that was us...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>119</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                link  ... words_in_summary\n",
              "1  https://tippecanoe.craigslist.org/app/d/fisher...  ...               83\n",
              "3  https://tippecanoe.craigslist.org/app/d/lafaye...  ...               21\n",
              "4  https://tippecanoe.craigslist.org/app/d/lafaye...  ...                4\n",
              "5  https://tippecanoe.craigslist.org/app/d/fisher...  ...               34\n",
              "6  https://tippecanoe.craigslist.org/app/d/lafaye...  ...               23\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-2pFMcQzlOa"
      },
      "source": [
        "# !wget https://dl.fbaipublicfiles.com/fasttext/vectors-english/crawl-300d-2M.vec.zip"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCEDPUxE0Zfy"
      },
      "source": [
        "# !unzip Text\\ classification/crawl-300d-2M.vec.zip"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bb4ZQrL-wGuW",
        "outputId": "9a2ecfe2-c0c4-4588-b41e-5a71e7c57589"
      },
      "source": [
        "embed_size = 300\n",
        "max_features = 6500\n",
        "maxlen = 350\n",
        "tokenizer = text.Tokenizer(num_words=max_features)\n",
        "tokenizer.fit_on_texts(list(filtered_data['Description']))\n",
        "EMBEDDING_FILE = 'Text classification/crawl-300d-2M.vec'\n",
        "print('loading embedding file')\n",
        "def get_coefs(word, *arr): return word, np.asarray(arr, dtype='float32')\n",
        "embeddings_index = dict(get_coefs(*o.rstrip().rsplit(' ')) for o in open(EMBEDDING_FILE,encoding=\"utf8\"))\n",
        "print('Done loading embedding file')\n",
        "word_index = tokenizer.word_index\n",
        "nb_words = min(max_features, len(word_index))\n",
        "embedding_matrix = np.zeros((nb_words, embed_size))\n",
        "for word, i in word_index.items():\n",
        "  if i >= max_features: continue\n",
        "  embedding_vector = embeddings_index.get(word)\n",
        "  if embedding_vector is not None: embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading embedding file\n",
            "Done loading embedding file\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZtSWukUOxdoZ"
      },
      "source": [
        "def build_model(body_flag,body_flag_test, X_train,Y_train,X_valid,Y_valid,check_point,early_stop,file_path, lr = 0.0, lr_d = 0.0, units = 0, dr = 0.0):\n",
        "    body_text_flag = body_flag\n",
        "    inp = Input(shape = (maxlen,))\n",
        "    print(nb_words)\n",
        "    x = Embedding(max_features , embed_size, weights = [embedding_matrix], trainable = False)(inp)\n",
        "\n",
        "    x = SpatialDropout1D(dr)(x)\n",
        "\n",
        "    x = Bidirectional(GRU(64, return_sequences = True))(x)\n",
        "    x = Conv1D(64, kernel_size = 1, padding = \"valid\", kernel_initializer = \"he_uniform\")(x)\n",
        "    avg_pool = GlobalAveragePooling1D()(x)\n",
        "    max_pool = GlobalMaxPooling1D()(x)\n",
        "    \n",
        "    # body_text_flag = Input(shape=[body_text_flag.shape[1]], name=\"body_text_flag\")\n",
        "    x = concatenate([avg_pool, max_pool])\n",
        "    x = Dense(1, activation = \"sigmoid\")(x)\n",
        "    model = Model(inputs = inp, outputs = x)\n",
        "    ra_val = RocAucEvaluation(validation_data=(X_valid, Y_valid), interval = 1)\n",
        "    model.compile(loss = \"binary_crossentropy\", optimizer = Adam(lr = lr, decay = lr_d), metrics = [\"accuracy\"])\n",
        "    history = model.fit(X_train , Y_train, batch_size = 64, epochs = 15, validation_data = (X_valid, Y_valid), \n",
        "                        verbose = 1, callbacks = [ra_val, check_point, early_stop])\n",
        "    model = load_model(file_path)\n",
        "    return model\n",
        "\n",
        "class RocAucEvaluation(Callback):\n",
        "    def __init__(self, validation_data=(), interval=1):\n",
        "        super(Callback, self).__init__()\n",
        "\n",
        "        self.interval = interval\n",
        "        self.X_val, self.y_val = validation_data\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        if epoch % self.interval == 0:\n",
        "            y_pred = self.model.predict(self.X_val, verbose=0)\n",
        "            score = roc_auc_score(self.y_val, y_pred)\n",
        "            print(\"\\n ROC-AUC - epoch: %d - score: %.6f \\n\" % (epoch+1, score))"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAbgMD8I7V2w"
      },
      "source": [
        "def build_model(body_flag,body_flag_test, X_train,Y_train,X_valid,Y_valid,check_point,early_stop,file_path, lr = 0.0, lr_d = 0.0, units = 0, dr = 0.0):\n",
        "    body_text_flag = body_flag\n",
        "    inp = Input(shape = (maxlen,))\n",
        "    x = Embedding(max_features, embed_size, weights = [embedding_matrix], trainable = False)(inp)\n",
        "    x = SpatialDropout1D(dr)(x)\n",
        "\n",
        "    x = Bidirectional(GRU(units, return_sequences = True))(x)\n",
        "    x = Conv1D(64, kernel_size = 2, padding = \"valid\", kernel_initializer = \"he_uniform\")(x)\n",
        "    avg_pool = GlobalAveragePooling1D()(x)\n",
        "    max_pool = GlobalMaxPooling1D()(x)\n",
        "    body_text_flag = Input(shape=[body_text_flag.shape[1]], name=\"body_text_flag\")\n",
        "    x = concatenate([avg_pool, max_pool, body_text_flag])\n",
        "    x = Dense(1, activation = \"sigmoid\")(x)\n",
        "    model = Model(inputs = [inp, body_text_flag], outputs = x)\n",
        "    ra_val = RocAucEvaluation(validation_data=([X_valid,body_flag_test], Y_valid), interval = 1)\n",
        "    model.compile(loss = \"binary_crossentropy\", optimizer = Adam(lr = lr, decay = lr_d), metrics = [\"accuracy\"])\n",
        "    history = model.fit([X_train,body_flag] , Y_train, batch_size = 64, epochs = 15, validation_data = ([X_valid,body_flag_test], Y_valid), \n",
        "                        verbose = 1, callbacks = [ra_val, check_point, early_stop])\n",
        "    model = load_model(file_path)\n",
        "    return model\n",
        "\n",
        "class RocAucEvaluation(Callback):\n",
        "    def __init__(self, validation_data=(), interval=1):\n",
        "        super(Callback, self).__init__()\n",
        "\n",
        "        self.interval = interval\n",
        "        self.X_val, self.y_val = validation_data\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        if epoch % self.interval == 0:\n",
        "            y_pred = self.model.predict(self.X_val, verbose=0)\n",
        "            score = roc_auc_score(self.y_val, y_pred)\n",
        "            print(\"\\n ROC-AUC - epoch: %d - score: %.6f \\n\" % (epoch+1, score))"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "AfVROWIbyJft",
        "outputId": "fc40d344-0403-416a-a0b3-2465fa4d6cc7"
      },
      "source": [
        "X_train, X_valid, Y_train, Y_valid = train_test_split(filtered_data.drop(['Condition'], axis=1), y, test_size = 0.2, random_state =1,stratify=y)\n",
        "raw_text_train = 'Title' + X_train[\"Title\"].astype(str) + ' ' + X_train[\"Description\"]\n",
        "raw_text_valid = 'Title' + X_valid[\"Title\"].astype(str) + ' ' + X_valid[\"Description\"]\n",
        "\n",
        "tk = text.Tokenizer(num_words = max_features, lower = True)\n",
        "tk.fit_on_texts(raw_text_train)\n",
        "X_train[\"text_seq\"] = tk.texts_to_sequences(raw_text_train)\n",
        "X_valid[\"text_seq\"] = tk.texts_to_sequences(raw_text_valid)\n",
        "\n",
        "print('padding')\n",
        "raw_text_train = pad_sequences(X_train.text_seq, maxlen = maxlen)\n",
        "raw_text_test = pad_sequences(X_valid.text_seq, maxlen = maxlen)\n",
        "\n",
        "\n",
        "file_path = \"best_model.hdf5\"\n",
        "check_point = ModelCheckpoint(file_path, monitor = \"val_acc\", verbose = 1,\n",
        "                      save_best_only = True, mode = \"max\")\n",
        "early_stop = EarlyStopping(monitor = \"val_acc\", mode = \"max\", patience = 5)\n",
        "test_flag = X_train[['ex_flag', 'new_flag', 'go_flag']].values\n",
        "body_flag_test = X_valid[['ex_flag', 'new_flag', 'go_flag']].values\n",
        "model = build_model(test_flag,body_flag_test,raw_text_train,Y_train,raw_text_test,Y_valid,check_point,early_stop,file_path,lr = 1e-3, lr_d = 0, units = 64, dr = 0.2)\n",
        "\n",
        "model.load_weights(file_path)\n",
        "predictions = model.predict([raw_text_test,body_flag_test]).reshape((raw_text_test.shape[0],))\n",
        "\n",
        "# pred = loaded_model.predict(X_valid, batch_size = 1024, verbose = 1)\n",
        "pred = np.where(predictions>=0.5,1,0)\n",
        "score = pd.DataFrame(pred)\n",
        "# print(Y_valid,score.astype(int))\n",
        "accuracy_val = accuracy_score(Y_valid, score.values)\n",
        "print('NN OOF accuracy: {}'.format(accuracy_val))"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "padding\n",
            "Epoch 1/15\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6888 - accuracy: 0.5235\n",
            " ROC-AUC - epoch: 1 - score: 0.729177 \n",
            "\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "10/10 [==============================] - 14s 1s/step - loss: 0.6888 - accuracy: 0.5235 - val_loss: 0.6582 - val_accuracy: 0.6125\n",
            "Epoch 2/15\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6334 - accuracy: 0.6724\n",
            " ROC-AUC - epoch: 2 - score: 0.749803 \n",
            "\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "10/10 [==============================] - 9s 866ms/step - loss: 0.6334 - accuracy: 0.6724 - val_loss: 0.6376 - val_accuracy: 0.6375\n",
            "Epoch 3/15\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5916 - accuracy: 0.7618\n",
            " ROC-AUC - epoch: 3 - score: 0.740198 \n",
            "\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "10/10 [==============================] - 9s 878ms/step - loss: 0.5916 - accuracy: 0.7618 - val_loss: 0.6209 - val_accuracy: 0.6500\n",
            "Epoch 4/15\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5531 - accuracy: 0.7712\n",
            " ROC-AUC - epoch: 4 - score: 0.733900 \n",
            "\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "10/10 [==============================] - 9s 875ms/step - loss: 0.5531 - accuracy: 0.7712 - val_loss: 0.6100 - val_accuracy: 0.6750\n",
            "Epoch 5/15\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5229 - accuracy: 0.7680\n",
            " ROC-AUC - epoch: 5 - score: 0.729649 \n",
            "\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "10/10 [==============================] - 9s 882ms/step - loss: 0.5229 - accuracy: 0.7680 - val_loss: 0.6060 - val_accuracy: 0.6812\n",
            "Epoch 6/15\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5023 - accuracy: 0.7806\n",
            " ROC-AUC - epoch: 6 - score: 0.734687 \n",
            "\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "10/10 [==============================] - 8s 861ms/step - loss: 0.5023 - accuracy: 0.7806 - val_loss: 0.6106 - val_accuracy: 0.6750\n",
            "Epoch 7/15\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4668 - accuracy: 0.8119\n",
            " ROC-AUC - epoch: 7 - score: 0.744922 \n",
            "\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "10/10 [==============================] - 8s 846ms/step - loss: 0.4668 - accuracy: 0.8119 - val_loss: 0.6192 - val_accuracy: 0.6250\n",
            "Epoch 8/15\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4393 - accuracy: 0.8182\n",
            " ROC-AUC - epoch: 8 - score: 0.746654 \n",
            "\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "10/10 [==============================] - 9s 866ms/step - loss: 0.4393 - accuracy: 0.8182 - val_loss: 0.5944 - val_accuracy: 0.6875\n",
            "Epoch 9/15\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.4077 - accuracy: 0.8605\n",
            " ROC-AUC - epoch: 9 - score: 0.753582 \n",
            "\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "10/10 [==============================] - 9s 868ms/step - loss: 0.4077 - accuracy: 0.8605 - val_loss: 0.5916 - val_accuracy: 0.6625\n",
            "Epoch 10/15\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3812 - accuracy: 0.8746\n",
            " ROC-AUC - epoch: 10 - score: 0.751378 \n",
            "\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "10/10 [==============================] - 8s 852ms/step - loss: 0.3812 - accuracy: 0.8746 - val_loss: 0.6066 - val_accuracy: 0.6500\n",
            "Epoch 11/15\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3385 - accuracy: 0.9028\n",
            " ROC-AUC - epoch: 11 - score: 0.742088 \n",
            "\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "10/10 [==============================] - 9s 874ms/step - loss: 0.3385 - accuracy: 0.9028 - val_loss: 0.6067 - val_accuracy: 0.7000\n",
            "Epoch 12/15\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.3100 - accuracy: 0.9013\n",
            " ROC-AUC - epoch: 12 - score: 0.732641 \n",
            "\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "10/10 [==============================] - 9s 873ms/step - loss: 0.3100 - accuracy: 0.9013 - val_loss: 0.6504 - val_accuracy: 0.6500\n",
            "Epoch 13/15\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2817 - accuracy: 0.9201\n",
            " ROC-AUC - epoch: 13 - score: 0.734845 \n",
            "\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "10/10 [==============================] - 8s 858ms/step - loss: 0.2817 - accuracy: 0.9201 - val_loss: 0.6520 - val_accuracy: 0.6750\n",
            "Epoch 14/15\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2484 - accuracy: 0.9342\n",
            " ROC-AUC - epoch: 14 - score: 0.739726 \n",
            "\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "10/10 [==============================] - 8s 860ms/step - loss: 0.2484 - accuracy: 0.9342 - val_loss: 0.6696 - val_accuracy: 0.6500\n",
            "Epoch 15/15\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.2271 - accuracy: 0.9326\n",
            " ROC-AUC - epoch: 15 - score: 0.740198 \n",
            "\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "10/10 [==============================] - 8s 857ms/step - loss: 0.2271 - accuracy: 0.9326 - val_loss: 0.6907 - val_accuracy: 0.6500\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-67-3c43907cf602>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mtest_flag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ex_flag'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'new_flag'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'go_flag'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mbody_flag_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_valid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ex_flag'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'new_flag'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'go_flag'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_flag\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbody_flag_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mraw_text_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mraw_text_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_valid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcheck_point\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mearly_stop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-66-9dce3fef95a2>\u001b[0m in \u001b[0;36mbuild_model\u001b[0;34m(body_flag, body_flag_test, X_train, Y_train, X_valid, Y_valid, check_point, early_stop, file_path, lr, lr_d, units, dr)\u001b[0m\n\u001b[1;32m     18\u001b[0m     history = model.fit([X_train,body_flag] , Y_train, batch_size = 64, epochs = 15, validation_data = ([X_valid,body_flag_test], Y_valid), \n\u001b[1;32m     19\u001b[0m                         verbose = 1, callbacks = [ra_val, check_point, early_stop])\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/saving/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'No file or directory found at {filepath}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0msaving_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_hdf5_filepath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mh5py\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             raise ImportError(\n",
            "\u001b[0;31mOSError\u001b[0m: No file or directory found at best_model.hdf5"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_-F1LSNyJ0T"
      },
      "source": [
        "inp = Input(shape = (maxlen,))\n",
        "x = Embedding(nb_words, embed_size, weights = [embedding_matrix], trainable = False)(inp)\n",
        "\n",
        "x = SpatialDropout1D(dr)(x)\n",
        "\n",
        "x = Bidirectional(GRU(units, return_sequences = True))(x)\n",
        "x = Conv1D(64, kernel_size = 1, padding = \"valid\", kernel_initializer = \"he_uniform\")(x)\n",
        "avg_pool = GlobalAveragePooling1D()(x)\n",
        "max_pool = GlobalMaxPooling1D()(x)\n",
        "\n",
        "x = concatenate([avg_pool, max_pool])\n",
        "x = Dense(1, activation = \"sigmoid\")(x)\n",
        "model = Model(inputs = [inp, body_text_flag], outputs = x)\n",
        "ra_val = RocAucEvaluation(validation_data=([X_valid,body_flag_test], Y_valid), interval = 1)\n",
        "model.compile(loss = \"binary_crossentropy\", optimizer = Adam(lr = lr, decay = lr_d), metrics = [\"accuracy\"])\n",
        "history = model.fit(X_train , Y_train, batch_size = 64, epochs = 15, validation_data = (X_valid, Y_valid), \n",
        "                    verbose = 1, callbacks = [ra_val, check_point, early_stop])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hczQ0fRA3hFP"
      },
      "source": [
        "model = load_model(file_path)\n",
        "model.load_weights(file_path)\n",
        "predictions = model.predict([raw_text_test,body_flag_test]).reshape((raw_text_test.shape[0],))\n",
        "\n",
        "# pred = loaded_model.predict(X_valid, batch_size = 1024, verbose = 1)\n",
        "pred = np.where(predictions>=0.5,1,0)\n",
        "score = pd.DataFrame(pred)\n",
        "# print(Y_valid,score.astype(int))\n",
        "accuracy_val = accuracy_score(Y_valid, score.values)\n",
        "print('NN OOF accuracy: {}'.format(accuracy_val))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}